{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPytWy3c5ARxmhPl7yNYij7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYa3MF1_FeWi","executionInfo":{"status":"ok","timestamp":1717636751612,"user_tz":-330,"elapsed":5702,"user":{"displayName":"Sivarama Sastry","userId":"04316292399280551917"}},"outputId":"d3d05f32-75af-457f-a8b9-f620ebdbb0ec"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/Image Binarization/novelty\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UL86WEGnF-V5","executionInfo":{"status":"ok","timestamp":1717636968576,"user_tz":-330,"elapsed":481,"user":{"displayName":"Sivarama Sastry","userId":"04316292399280551917"}},"outputId":"6453c239-a096-48a3-83a9-f74b674c4ffc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Image Binarization/novelty\n"]}]},{"cell_type":"code","source":["import cv2\n","import os\n","import numpy as np\n","\n"],"metadata":{"id":"sv7KY4sVGR1i","executionInfo":{"status":"ok","timestamp":1717636764021,"user_tz":-330,"elapsed":686,"user":{"displayName":"Sivarama Sastry","userId":"04316292399280551917"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["pip install segmentation_models_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Ew1_TRCmGXm6","executionInfo":{"status":"ok","timestamp":1717636357534,"user_tz":-330,"elapsed":78384,"user":{"displayName":"Sivarama Sastry","userId":"04316292399280551917"}},"outputId":"43d2188d-bff3-4875-e21d-e6d2052960c9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation_models_pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m102.4/106.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.18.0+cu121)\n","Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation_models_pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0+cu121)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.23.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (24.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.31.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=a907f87bf7334617cf28c7a9125041706ddf8c0ec14fa3597f5f5d794b6180ab\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=fbf2cb4ff41540d198ce3676e64c4bff8b84a66ea4d47edbe8d8d1490b3986b0\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.3 timm-0.9.2\n"]}]},{"cell_type":"code","source":["import segmentation_models_pytorch as smp"],"metadata":{"id":"y4pM_g4jGWGj","executionInfo":{"status":"ok","timestamp":1717636776868,"user_tz":-330,"elapsed":9676,"user":{"displayName":"Sivarama Sastry","userId":"04316292399280551917"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","pip install torch"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"rJ9LWMFkHBCc","executionInfo":{"status":"ok","timestamp":1717636787772,"user_tz":-330,"elapsed":7147,"user":{"displayName":"Sivarama Sastry","userId":"04316292399280551917"}},"outputId":"c4601498-1999-4c03-b097-8311f0fa5c4f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"yWtFxjLhG21W","executionInfo":{"status":"ok","timestamp":1717636788243,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sivarama Sastry","userId":"04316292399280551917"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCDzB9bwFWiy","executionInfo":{"status":"ok","timestamp":1717637147734,"user_tz":-330,"elapsed":60131,"user":{"displayName":"Sivarama Sastry","userId":"04316292399280551917"}},"outputId":"28f621b9-f227-4082-d863-837662e16d8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original Image Dimensions: 9371 x 843\n","Reconstructed Image Dimensions: 9371 x 843\n","Reconstructed image saved as output.png\n"]}],"source":["\n","\n","# Function to divide the input image into patches\n","def divide_into_patches(image_path):\n","    # Read the image using OpenCV\n","    original_image = cv2.imread(image_path)\n","\n","    # Get the original width and height\n","    original_height, original_width, _ = original_image.shape\n","\n","    # Calculate the required padding for the right and bottom sides\n","    pad_right = 256 - (original_width % 256) if original_width % 256 != 0 else 0\n","    pad_bottom = 256 - (original_height % 256) if original_height % 256 != 0 else 0\n","\n","    # Pad the image with white color only on the right and bottom sides\n","    padded_image = cv2.copyMakeBorder(original_image, 0, pad_bottom, 0, pad_right, cv2.BORDER_CONSTANT, value=(255, 255, 255))\n","\n","    # Cut the image into 256x256 patches\n","    patches = []\n","    for i in range(0, padded_image.shape[0], 256):\n","        for j in range(0, padded_image.shape[1], 256):\n","            patch = padded_image[i:i+256, j:j+256]\n","            patches.append(patch)\n","\n","    return patches, original_width, original_height\n","\n","# Function to apply the model parameters to each patch and obtain predictions\n","def apply_model_to_patches(model, patches):\n","    predictions = []\n","    for patch in patches:\n","        # Convert patch to tensor and unsqueeze to add batch dimension\n","        patch_tensor = torch.tensor(patch).permute(2, 0, 1).unsqueeze(0).float()\n","\n","        # Apply model to patch\n","        with torch.no_grad():\n","            prediction = model(patch_tensor)\n","\n","        # Append prediction to list\n","        predictions.append(prediction.squeeze(dim=0).cpu().numpy())\n","\n","    return predictions\n","\n","# Function to reconstruct the total image from the predictions of all patches\n","def reconstruct_image(predictions, original_width, original_height):\n","    # Determine the dimensions of the stitched image\n","    cols = (original_width + 255) // 256  # Calculate the number of columns\n","    rows = (original_height + 255) // 256  # Calculate the number of rows\n","    width = cols * 256\n","    height = rows * 256\n","\n","    # Create a blank canvas to stitch the images onto\n","    stitched_image = 255 * np.ones((height, width, 1), dtype=np.uint8)\n","\n","    # Reconstruct the image from predictions of all patches\n","    idx = 0\n","    for i in range(rows):\n","        for j in range(cols):\n","            if idx < len(predictions):\n","                y = i * 256\n","                x = j * 256\n","                stitched_image[y:y+256, x:x+256] = (torch.tensor(predictions[idx]).permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n","                idx += 1\n","\n","    # Crop the stitched image to the original dimensions\n","    cropped_stitched_image = stitched_image[:original_height, :original_width].copy()\n","    return cropped_stitched_image\n","\n","# Example usage:\n","input_image_path = \"input.png\"  # Provide the path to your input image\n","model_name_to_load = \"BCE_FPN_epoch60.pth\"  # Provide the path to your model file\n","\n","# Load the model\n","model = smp.FPN(\n","            encoder_name='resnet34',\n","            in_channels=3,\n","            classes=1,\n","            activation='sigmoid',\n","            encoder_weights='imagenet'\n","        )\n","model.load_state_dict(torch.load(model_name_to_load, map_location=torch.device('cpu')))\n","model.eval()\n","\n","# Divide the image into patches\n","patches, original_width, original_height = divide_into_patches(input_image_path)\n","\n","# Apply the model parameters to each patch and obtain predictions\n","predictions = apply_model_to_patches(model, patches)\n","\n","# Reconstruct the total image from the predictions of all patches\n","reconstructed_image = reconstruct_image(predictions, original_width, original_height)\n","\n","# Save the reconstructed image\n","output_image_path = \"output.png\"  # Provide the path to save the reconstructed image\n","cv2.imwrite(output_image_path, reconstructed_image)\n","\n","print(\"Original Image Dimensions:\", original_width, \"x\", original_height)\n","print(\"Reconstructed Image Dimensions:\", reconstructed_image.shape[1], \"x\", reconstructed_image.shape[0])\n","print(f\"Reconstructed image saved as {output_image_path}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"MkFOMnZgF9Ti"},"execution_count":null,"outputs":[]}]}